시계열 분석
===========

통계 기본
---------

### 평균

#### 산술 평균

일반적으로 사용하는 $\sum_{i=1}^{n}$ $\frac{a_i}{n}$ 의 평균

#### 기하 평균

곱셈으로 게산하고 제곱근으로 나누는 평균. $\sqrt[n]{\Pi_{i=1}^{n} a_i}$

#### 조화 평균

분수 계산에 쓰이는 평균. 잘 안 쓰인다. $\frac{n}{\sum_{i=1}^{n} \frac{1}{a_i}}$

#### 가중 평균

산술 평균에 가중치를 둔 것. $\frac{\sum_ {i=1}^{n}w_ i{a_ i}}{\sum_ {i=1}^{n} w_ i}$

### 분산

#### 표본 분산

$s^2 = \frac{\sum(x - \overline{x})^2}{n-1}$  
여기서 n-1의 -1은 자유도를 제한 값이다. 분산은 평균이 정해져야 계산 가능하기 때문에 제한 사항 1을 뺀 것이다. 제약사항이 많을수록(자유도가 클수록) 분산은 커진다.

#### 모집단 분산

$\sigma^2 = \frac{\sum(x - \mu)^2}{N}$

### 왜도

데이터의 편향성을 보여주는 근거이다.  
$skewness = \frac{\sum_{i=1}^n (Y_i - \overline{Y})^3}{(N-1)s^3}$  
양수이면 왼쪽으로, 음수이면 오른쪽으로 치우친 분포이다.

### 첨도

데이터 분포의 고르기를 나타낸다.  
$Kurtosis = \frac{\sum_{i=1}^n (Y_i - \overline{Y})^4}{(N-1)s^4}$  
정규분포의 경우는 3이며 높을수록 평균에 몰려있는 분포이다.

### 이상점, 특이점, Outlier

모두 같은 말이다.  
평균에서 떨어진 극단점을 말한다. 이 자료의 근거를 밝히거나 무시하거나의 두 가지 대응을 택할 수 있다.  
물론 밝히는 것이 정답.

가설 검정
---------

### 가설(주장)

검증 가능한 것을 주장해야 한다. 예시로 $$양치기는\space주로\space거짓말을\space한다$$를 주장으로 삼겠다. 이 때 이 주장에 대한 반박은 $$양치기라고\space거짓말을\space더\space많이\space하지는 \space않는다$$일 것이다.

### 검정 모형

#### 귀무가설(Null Hypothesis)

주장에 반박하여 검증하고자 하는 내용이다. 여기서는 $양치기라고\space거짓말을\space더\space많이\space하지는 \space않는다$는 것이다.

#### 대립가설(대안가설, Alternative Hypothesis)

귀무가설에 대한 반박이다. 결과적으로 대립가설이 거짓임을 증명하여 귀무가설을 증명시킨다. 여기서는 $양치기는\space주로\space거짓말을\space한다$ 이다.

### 조사

#### 전수조사

모집단 전체를 조사한다. 시간이 많이 걸리며 조사 자체가 영향을 끼칠 수도 있어 반드시 정확하지도 않다.

#### 표본조사

일부 표본을 추출하여 조사한다. 표본 추출 과정에서 편향성이 생길 수 있다.

##### 표본 추출 방법

편향성을 줄이는 것이 그 목적이다.

1.	Bootstraping : 표본을 여러번에 나누어 추출하는 것이다. 중복을 허용하거나 제하는 방식을 택할 수 있다.
2.	Allocational Sampling : 모집단의 세부 특성에 따라 집단을 나누고 각각을 조사, 종합하는 방식이다. 특성에 따라 모집단이 잘 나누어지는지 불명확하다는 단점이 있다.
3.	Bias Adjustment : 그냥 조사하고 난 뒤 기존에 알려진 편향성을 계산에 포함하는 방식. 이미 알려진 편향성이라는 항에 대한 근거를 제시해야함이 단점.

### Central Limit Theorem, CLT

표본 평균의 집합은 모집단의 평균을 중심으로 정규분포한다. 즉 $$\overline{X} \thicksim N(\mu, \frac{\sigma^2}{n})$$ 여기서 $\mu$는 모집단의 평균이고 $\sigma^2$는 모집단의 분산이다.  
다음의 특징을 갖는다.  
1. 원집단의 특성관 관계없이 표본 평균의 분포는 정규분포이다.  
1. 표본 크기가 클 수록 표본 평균의 분산은 낮아진다.  
1. 표본 분산은 대체로 모집단 분산에 근접한다. 곧 표본 평균과 분산으로 모집단의 평균과 분산 추정이 가능하다.  
1. 결국 CLT의 추정으로 모집단의 분포를 알 순 없다.

### 통계적 가설 검정

표본을 여러번 뽑지 않아도 결국 내 표본이 정규분포에 속할 것을 알고 있다.  
즉 예시에서 일반인들의 평균 거짓말 횟수를 K, 분산을 H라고 했을 때  
N명의 양치기를 대상으로 거짓말 횟수를 얻어 평균을 X라고 하고  
만약 양치기의 거짓말 횟수가 일반인들과 큰 차이가 없다면 양치기 표본은 곧 일반인 표본이고  
이 표본의 평균인 X는 $N(K, \frac{H}{N})$을 따를 것이다.  
만약 귀무가설처럼 양치기라고 더 거짓말을 많이 하지 않는다면 X는 평균 K에 근접해야 한다.

### 의사결정

과연 근접하다는 것이 무슨 의미를 갖고 있을까?  
여기서 분산이 의미를 갖는다. 우리는 표본 평균이 정규분포를 따른다는 것을 알고 있으며 정규분포의 분산 모양에서 우리가 찾은 표본 평균이 얼마나 평균에 가까운 경우인지 알 수 있게 된다. 표준 정규분포를 이용하면 더욱 편하다.  
$$표준정규분포 : Z = \frac{\overline{x} - 모집단평균}{모집단표준편차}$$  
표준정규분포에서 5% 오차 허용 범위는 -1.96~+1.96이다.

### 관련 용어

-	Level of Significance : 앞에서 5%와 같이 경계점으로 쓰는 기준  
-	Left-Tail/Right-Tail Test : 꼬리 검정. 좌측, 우측 꼬리에 표본 값이 속하는지 확인하는 검정  
-	P-value : 귀무가설이 타당할 정도를 간단히 P-value라 부른다. 앞서의 경우 타당할 가능성이 95%이므로 P-value는 0.95가 된다.  
-	Critical-value : 특정 P-value를 위한 경계 기준. 앞서의 경우 $\plusmn 1.96$이다.  

### 가설 검정의 한계

-	결국 평균 추정에 불과하다. 모집단의 분포에 대해서는 알 수 없으므로 그 왜도나 첨도에 따라 영향을 받을 수 있는 데이터 분석에는 한계가 있다.  
-	내가 택한 표본이 맞는지 알 수 없다.

	-	Type1 ERROR : 아웃라이어가 제외된 표본을 보고 오판할 수 있다.
	-	Type2 ERROR : 아웃라이어가 상당수인 표본을 보고 오판할 수 있다.

회귀분석
--------

### 회귀?

통계 분석에서 회귀란 둘 이상의 변량 사이의 관계식을 적용하는 행위를 말한다.  
예를 들어 변량 Y와 변량 X 사이에 $Y = aX + b + e$ 를 적용시키는 것이다.(이 식은 1차 선형 회귀이다.)  
회귀 분석을 통한 목표는 e(에러)의 평균이 0이 되도록 하는 것.  
따라서 e의 평균이 최소가 되도록 parameter 값이 좁혀지기 때문에 회귀라고 부른다. 다만 이렇게는 정확한 Y값을 계산할 수 없고 Y의 평균에 근사하는 값에 추정할 수 있을 뿐이다.  
따라서 회귀만으로 끝나는 게 아니라 회귀의 결과를 평가할 수 있어야 한다.

### 회귀 분석의 평가

$$ Y = AX + B + E $$  
식을 다시 살펴보자.  
이 식에서 E를 제외한 $AX + B$와 $E$의 두개의 항으로 나눠 볼 수 있을 것이다. 여기서 앞의 항이 식에 영향을 강하게 미치면 회귀 분석이 유용한 것이고 뒤의 항이 영향을 강하게 미치면 회귀 분석이 유용하지 않았다는 의미로 볼 수 있다.  
이 정도를 측정하는 지표를 $R^2$, 즉 R-square라고 부른다. 이 값이 1이면 $E$가 존재하지 않는 것이고 이 값이 0이면 $AX+B$가 아무것도 설명하지 못하는 상황이다. R-square의 계산법은 후술.

### 가설 검정

평가를 위해 회귀 분석 식을 평가하는 방법 중 하나이다.  
귀무 가설을 $Y = C + E$로 두고  
대립가설은 $Y = AX + B + E$로 두어 제시된 회귀식을 전체 검정할 수 있고 혹은 각 Parameter에 따라  
$Y = B + E$ vs $Y = AX + B + E$,  
$Y = AX + E$ vs $Y = AX + B + E$로 두고 검정할 수 있다.

### 신뢰 구간

평가를 위해 신뢰구간을 활용할 수 있다. X 변량의 평균과 분산으로 Y 또한 회귀식으로 알 수 있고 X에 따른 Y의 신뢰구간 안에 얼마만큼의 정보가 있는지를 평가할 수도 있다.

### 주의점

-	1차 회귀 외에도 2차나 3차 회귀를 시도해야 할 수 있다.  
-	이분산 : 변수 중에는 X가 특정 범위일 때 Y의 분산이 다른 경우도 있다. 이 떄는 이 둘 사이에 관계가 있는 것으로 보고 추정해야 한다.  
-	다중공산성(Multicollinearity) : 변수들간에 관계가 있어 데이터가 꼬이는 경우이다. 높은 상관성이 있을수록 Parameter의 분산이 증가하여 예측력이 나빠진다.

시계열 분석
-----------

### 시계열 분석은 가짜일까

시계열 분석의 목적을 미래 예측으로 두면 안 된다.  
미래예측에 도움을 줄 목적이거나 과거 데이터에서 어떤 값들 사이의 상관관계를 얻고자 할 때 사용해야 한다.

### 특징

시간을 고려하고 행하는 분석이므로 다른 변량이 있을 수도 있지만 없어도 관계없다. 즉 분석 목표가 되는 데이터와 시간으로 이미 두 가지 데이터를 얻기 떄문이다.

### 해체

규칙성 패턴과 불규칙 패턴의 합으로 고려한다.

-	규칙성 패턴
	-	자기상관성(Autocorrelativeness) : 이전 결과에 의해 발생하는 결과
	-	동평균(MovingAverage) : 이전의 불규칙한 사건이 이후의 결과에 편향성 을 주는 것
-	불규칙 패턴
	-	불규칙오차(WhiteNoise) : 일반적으로 $N(0,\sigma^2)$에서 얻어질 것으로 예상되는 값. 이렇게 두면 해석에 용이하다.  

여기서 AR모델, MA모델, ARMA모델, ARIMA 모델이 발생한다. 알려진 모델들은 이 패턴에서 개량, 변화한 것인데 위 모델들에서 시계열의 움직임이 정규분포를 따르기 떄문에 해석에 편이가 있다.

### 알려진 모델

#### AR모델

이전 값이 이후 값에 영향을 미치고 있는 모델이다. 보통 이전 값이 크면 다음 값이 작거나 다음 값이 작으면 그 다음 값은 크거나 하는 경향이다.  
직전 값의 영향을 받기도 하지만 어떤 간격을 두고 지연 발생하기도 한다. 평균으로 돌아가려는 경향을 가진 것들로 대부분의 금융 정보가 이 경향을 가지고 있다. 이전 몇 개 값의 영향을 받느냐에 따라 AR(n) 모델이라고 한다. 다음이 그 AR(n) 모델이다.  
$$X_ t = c + \sum_ {i=1}^n \psi_ i X_ {t-i}+\epsilon_ t$$

#### MA모델

시간에 따라 목적 데이터의 평균값이 지속적으로 증가하거나 감소하는 경향이 있을 것이라고 예상하는 모델. 예를 들어 전기 사용량의 경우 여름이 되면서 사용량이 많아지고 겨울이 되면서 떨어지는 경향이 있을 것이다. 전기 사용료가 크게 부담되지 않는다면 지난달 사용량이 이번달 사용량에 영향을 주진 않을 것이다. 증권가에서 최근 50일의 평균 50MA, 15일의 평균 15MA를 비교할 때 얘기하는 MA가 이것이다. 즉 이전 몇 개 값에 영향을 받느냐에 따라 MA(n) 모델이라고 한다. 아래 식에서 결국 이전 X의 값에 영향받지 않음을 살펴보자.  
$$X_ t = c + \sum_ {i=1}^n \psi_ i \epsilon_ {t-i}+\mu\epsilon_ t$$

#### ARMA모델

AR모델과 MA모델을 합친 것으로 통상 ARMA(2, 2)면 유의미한 데이터를 얻는다. ARMA(P, Q)식은 아래와 같다.  
$$X_ t = c + \sum_ {i=1}^P \psi_ i X_ {t-i}+\sum_ {i=1}^Q \phi_ i \epsilon_ {t-i}+\epsilon_ t$$

#### ARIMA모델

Autocorrelativeness Intgrated Moving Average로 Integrated는 추세를 반영함을 의미한다.

추세(Momentum)관계는 어떤 변수가 증가할 때 목적 변수도 증가하거나 감소하는 경향을 의미한다. 상관관계와는 다르다.

-	상관관계(Correlation)

	-	양수인 경우 : X가 크면 Y도 크다.  
	-	음수인 경우 : X가 크면 Y는 작다.  

-	추세관계(Cointegration)

	-	양수인 경우 : X가 증가하면 Y도 증가한다.  
	-	음수인 경우 : X가 증가하면 Y는 감소한다.

이 떄 WhiteNoise의 추세는 고려하지 않는데 앞서 WhiteNoise는 정규분포 내에서 뽑은 임의값으로 본다고 했으므로 여기에 추세가 있다고 가정하는 것은 상충되기 떄문이다. ARIMA(P, D, Q)의 식은 아래와 같다.  
$$X_ {t, \space d} = c + \sum_ {i=1}^P \psi_ i X_ {t-i, \space d}+\sum_ {i=1}^Q \phi_ i \epsilon_ {t-i}+\epsilon_ t$$  
여기서 d는 차분 횟수를 말한다.  
- 차분 : 이전 값과 현재 값의 차, 1차 차분이라함은 $X_ t - X_ {t-1}$ 이고  
d차 차분은 차분합 간의 뺄셈으로 $X_ t - dX_ {t-1} - \frac{d(d-1)}{2}X_ {t-2} + \dots -(-1)^dX_ {t-d}$ 이며 다시 쓰면  
$(1 - B)^dX_ t,\space 단\space B^aX_ t = X_ {t-a}$  
로 쓸 수 있다. 즉 ARIMA의 식은 $$X_ {t, \space d} = (1 - B)^dX_ t = c + \sum_ {i=1}^P \psi_ i X_ {t-i, \space d}+\sum_ {i=1}^Q \phi_ i \epsilon_ {t-i}+\epsilon_ t,\space 단\space B^aX_ t = X_ {t-a}$$  
이다.

### 정상성

뚜렷한 추세가 없으며 분산이 시간이 흘러도 일정한 경우 정상성을 갖는다고 말한다.  
추세가 있는 경우 차분을 통해 이 추세를 제거할 수 있다.  
가장 완벽한 경우는 WhiteNoise이다.
